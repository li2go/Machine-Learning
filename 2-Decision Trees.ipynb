{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 决策树是一种基本的分类与回归方法。它可以认为是if-then 规则的集合，也可以是认为是定义在特征空间与类空间上的条件概率分布。\n",
    " \n",
    " ### 它包括三个步骤\n",
    " \n",
    " 特征选择\n",
    " \n",
    " 决策树的生成\n",
    " \n",
    " 决策树的修剪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树模型\n",
    "\n",
    "决策树由结点和有向边组成，不能再往下分的叫叶节点，能往下分的叫做内部结点。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd #基于numpy的数据分析包，利用pandas进行运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['y', 'y', 'y'],\n",
       "       ['y', 'y', 'y'],\n",
       "       ['y', 'n', 'n'],\n",
       "       ['n', 'y', 'n'],\n",
       "       ['n', 'y', 'n']], dtype='<U1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#加载数据集\n",
    "dataSet = [['y','y','y'],\n",
    "              ['y','y',\"y\"],\n",
    "              ['y','n',\"n\"],\n",
    "              ['n','y',\"n\"],\n",
    "              ['n','y',\"n\"]]\n",
    "labels = ['no surfacing','flippers','lables']\n",
    "dataSet = np.array(dataSet) #转换成向量的形式\n",
    "labels = np.array(labels)   #只有转换成向量的形式才能计算\n",
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no surfacing</th>\n",
       "      <th>flippers</th>\n",
       "      <th>lables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  no surfacing flippers lables\n",
       "0            y        y      y\n",
       "1            y        y      y\n",
       "2            y        n      n\n",
       "3            n        y      n\n",
       "4            n        y      n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#转换成列表的形式\n",
    "data = pd.DataFrame(data = dataSet,columns = labels)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xiangnongzhi(data):\n",
    "    labels_data = data.iloc[:,-1]\n",
    "    labels_size = labels_data.size\n",
    "    zidian = {}\n",
    "    list = []\n",
    "    for i in labels_data:\n",
    "        if i not in zidian:\n",
    "            zidian[i] = 1\n",
    "        else:\n",
    "            zidian[i] += 1\n",
    "    for key,value in zidian.items():\n",
    "        list.append(value)\n",
    "        a = np.array(list) / labels_size\n",
    "        b = np.sum(-a * np.log2(a))\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xiangnongzhi(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zuiyou(data):\n",
    "    a = data.index.size\n",
    "    fetures = data.columns[:-1]\n",
    "    c_dic = {}\n",
    "    esum = 0\n",
    "    for i in fetures:\n",
    "        data1 = data[i]\n",
    "        lei = pd.unique(data1)\n",
    "        for j in lei:\n",
    "            data_son = data[data1 == j]\n",
    "            fenzi = data_son.index.size\n",
    "            ent = xiangnongzhi(data_son) * fenzi / a\n",
    "            esum += ent\n",
    "        c_dic[i] = esum\n",
    "    zuiyou = sorted(c_dic.items(),key = lambda z:z[1] , reverse=False)[0][0]        \n",
    "    return zuiyou\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no surfacing'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zuiyou = zuiyou(data)\n",
    "zuiyou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#看标签中一共有几个样本，作为计算总信息熵的分母\n",
    "H_y_fenmu = data.index.size \n",
    "H_y_fenmu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H_y_yes = (data.iloc[:,-1] == 'y').sum()\n",
    "H_y_yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H_y_no = (data.iloc[:,-1] == 'n').sum()\n",
    "H_y_no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H_y_pi = np.array([H_y_yes/H_y_fenmu,H_y_no/H_y_fenmu])\n",
    "H_y_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lables_data = data.iloc[:,-1] \n",
    "lables_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步 计算香农值\n",
    "def calcShannonEnt_labels(data):\n",
    "    labels_data = data.iloc[:,-1]  #取出最后一列\n",
    "    labels_size = labels_data.size  #返回的是5 最后的总的标签数\n",
    "    #统计各个种类，以及不同种类数\n",
    "    dict_label = {}#定义一个字典 往里面放标签的种类\n",
    "    \n",
    "    #定义一个空列表，放入值\n",
    "    H_y = []\n",
    "    \n",
    "    #构建一个循环\n",
    "    for i in labels_data:\n",
    "        if i not in dict_label: #if i 不在那个字典里，就把i放进去\n",
    "            dict_label[i] = 1\n",
    "        else:                   #if i 在这个字典里，自加1，起到一个计数的作用\n",
    "            dict_label[i] += 1\n",
    "            \n",
    "    #>>>print(dict_label)\n",
    "    #>>>{'y': 2, 'n': 3}\n",
    "            \n",
    "    #再次构建一个循环，提取并运用里面的数字\n",
    "    #字典(Dictionary) items() 函数以列表返回可遍历的(键, 值) 元组数组\n",
    "    for key,value in dict_label.items():\n",
    "        H_y.append(value)\n",
    "    H_y = np.array(H_y) / labels_size \n",
    "    H_y = np.sum(-H_y * np.log2(H_y)) #得出的结果是总的香农值 也就是y的概率和n的概率放在一起的香农值\n",
    "    return H_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcShannonEnt_labels(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#求得是一个最优的变量\n",
    "def calcShannonEnt_feture(data):\n",
    "    data_size = data.index.size #求总的样本数，此案例为5\n",
    "    fetures = data.columns[:-1] #获取列标签，除了最后一列\n",
    "    \n",
    "    #>>>print(fetures)\n",
    "    #>>>Index(['no surfacing', 'flippers'], dtype='object')\n",
    "    \n",
    "    #columns[:-1]中间没有逗号\n",
    "    best_feture_dic = {} \n",
    "    for feture in fetures: #循环列中的每一列\n",
    "        feture_son = data[feture] #获取数据中的特征的列,每一列的特征值\n",
    "        unique_feture = pd.unique(feture_son) #取出列中唯一的特征值,除了最后一列\n",
    "        \n",
    "        #>>>print(unique_feture)\n",
    "        #>>>['y' 'n']\n",
    "        #   ['y' 'n']\n",
    "        \n",
    "        #>>>print(feture_son)\n",
    "        #>>>获取的是每一个特征的特征向量\n",
    "        \n",
    "        #计算的是最优的\n",
    "        Ent_sum = 0 \n",
    "        for u_feture in unique_feture:\n",
    "            \n",
    "            #分别按照x1和x2进行y和n的划分\n",
    "            data_son = data[feture_son == u_feture]\n",
    "            \n",
    "            #print(data_son)\n",
    "                  #no surfacing flippers lables\n",
    "                #0            y        y      y\n",
    "                #1            y        y      y\n",
    "                #2            y        n      n\n",
    "                 # no surfacing flippers lables\n",
    "                #3            n        y      n\n",
    "                #4            n        y      n\n",
    "                # no surfacing flippers lables\n",
    "                #0            y        y      y\n",
    "                #1            y        y      y\n",
    "                #3            n        y      n\n",
    "                #4            n        y      n\n",
    "                  #no surfacing flippers lables\n",
    "                #2            y        n      n\n",
    "            fenzi = data_son.index.size  \n",
    "            #print(fenzi)\n",
    "            #3 2 4 1\n",
    "            \n",
    "            Ent = calcShannonEnt_labels(data_son) * fenzi / data_size \n",
    "            Ent_sum += Ent   \n",
    "        \n",
    "        best_feture_dic[feture] = Ent_sum \n",
    "        #print(best_feture_dic)\n",
    "    best_feture = sorted(best_feture_dic.items(),key=lambda z:z[1],reverse=False)[0][0]  #按照第二个元素排列 升序\n",
    "    \n",
    "    return best_feture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no surfacing'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcShannonEnt_feture(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no surfacing'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feture = calcShannonEnt_feture(data)\n",
    "best_feture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_Tree(data,best_feture):\n",
    "    best_feture_son = pd.unique(data[best_feture])\n",
    "    #print(best_feture_son)\n",
    "    split_result = []\n",
    "    sum_data = 0\n",
    "    for feture_son in best_feture_son:\n",
    "        #循环最优的特征列的y和n\n",
    "        split_data = data[data[best_feture]==feture_son] \n",
    "        split_data_label = split_data.iloc[:,-1] #取出最优列的最后一列，也就是标签的那列\n",
    "        \n",
    "        #按照特征列划分之后标签中的类别\n",
    "        unique_size = pd.unique(split_data_label).size\n",
    "       \n",
    "        if unique_size == 1: #如果划分后的标签类别只有一个\n",
    "            \n",
    "            #>>>print([best_feture,feture_son])\n",
    "            #>>>['no surfacing', 'n']\n",
    "            \n",
    "            split_result.append([best_feture,feture_son]) #加到那个空列表中\n",
    "            sum_data += split_data.index.size #计数有几个\n",
    "            \n",
    "            #>>>print(sum_data)\n",
    "            #>>>2\n",
    "            \n",
    "        else: #如果不止一个类别\n",
    "            \n",
    "            drop_data = split_data.drop(columns = best_feture) #删掉最优的那一列，剩下还可以继续划分的特征\n",
    "            #print(drop_data)\n",
    "            split_result.append([best_feture,feture_son,drop_data])\n",
    "    return split_result,sum_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['no surfacing', 'y',   flippers lables\n",
       "   0        y      y\n",
       "   1        y      y\n",
       "   2        n      n], ['no surfacing', 'n']], 2)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_Tree(data,best_feture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT(data):\n",
    "    Split_result = []\n",
    "    all_data = data.index.size\n",
    "    all_data_columns = data.columns[:-1].size\n",
    "    sum_data = 0\n",
    "    sum_labels = 0\n",
    "    while 1:\n",
    "        # 所有的样本已经划分完毕\n",
    "        if sum_data == all_data:\n",
    "            print('样本划分完毕')\n",
    "            return Split_result\n",
    "        if sum_labels == all_data_columns:\n",
    "            if sum_data == all_data:\n",
    "                print('标签使用完毕,且样本完全划分完毕')\n",
    "                return Split_result\n",
    "            else:\n",
    "                print('标签使用完毕,但是样本未完全划分')\n",
    "                return Split_result\n",
    "            \n",
    "        best_feture = calcShannonEnt_feture(data)\n",
    "        sum_labels +=1\n",
    "        split_result,sum_data_son = split_Tree(data,best_feture)\n",
    "        sum_data += sum_data_son\n",
    "    \n",
    "        for i in split_result:\n",
    "            if len(i) == 2:\n",
    "                Split_result.append(i)\n",
    "            else:\n",
    "                data = i[-1]\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本划分完毕\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['no surfacing', 'n'], ['flippers', 'y'], ['flippers', 'n']]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
